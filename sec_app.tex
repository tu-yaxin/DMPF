\section{Applications}
\Yaxin{This section is highly incomplete... Each subsection contains some to do list and I'll do more research. } 

For convenience of discussion DMPF applications, we use $\DMPF_{t, N, \GG}$ to denote a DMPF scheme for $t$-point functions with domain $[N]$ and output group $\GG$. 

\begin{table*}
  \caption{Concrete applications of DMPF. }
  \label{tab:app_parameters}
	\begin{tabular}{ccc}
    \toprule
		Concrete application &\makecell{Cost in terms of DMPF\\per correlation/execution}& Typical DMPF parameters \\
    \midrule
		PCG for OLE from Ring-LPN &\makecell{seedsize $\propto$ DMPF.$keysize$\\expand time $\propto$ DMPF.$FullEval()$} & \makecell{$t = 5^2, 16^2, 76^2$\\$N = 2^{20}$}  \\
		PSI-WCA & \makecell{communication $\propto$ DMPF.$keysize$\\client computation $\propto$ DMPF.$Gen()$\\server computation $\propto$ DMPF.$Eval()$} & \makecell{$t = $any\\$N = 2^{128}$}\\
    \bottomrule
	\end{tabular}
\end{table*}

\subsection{PCG for OLE from Ring-$\LPN$}

We begin by briefly introducing the protocol of PCG for OLE from Ring-$\LPN$ assumption, proposed in \cite{cryptoeprint:2022/1035}. 

\paragraph{The PCG protocol for OLE correlation.}The hardness assumption we will make use of is a variant of Ring-$\LPN$, called module-$\LPN$ assumption. 
\begin{definition}[Module-$\LPN$]\label{def:module-LPN}
    Let $c\ge 2$ be an integer, $R = \ZZ_p[X]/F(X)$ for a prime $p$ and a deg-$N$ polynomial $F(X)\in \ZZ_p[X]$, and $\mathcal{HW}_{R,t}$ be the uniform distribution over \`weight-$t$\' polynomials in $R$ whose degree is less than $N$ and has at most $t$ nonzero coefficients. 
    %(We write $\mathcal{HW}_t$ when $R$ is clear from the context. )
     For $R=R(\lambda)$, $t=t(\lambda)$ and $m=m(\lambda)$, we say that the module-$\LPN$ problem $R^c$-$\LPN$ is hard if for every nonuniform polynomial-time probabilistic distinguisher $\cA$, it holds that 
    \[
        |\Pr[\cA(\{\vec{a}^{(i)}, \ipd{\vec{a}^{(i)}}{\vec{s}}+\vec{e}^{(i)}\}_{i\in [m]})] - \Pr[\cA(\{\vec{a}^{(i)},\vec{u}^{(i)}\}_{i\in [m]})] \le \mathsf{negl}(\lambda)
    \]
    where the probabilities are taken over the randomness of $\cA$, random samples $\vec{a}^{(1)},\cdots, \vec{a}^{(m)}\leftarrow R^{c-1}$, $\vec{u}^{(1)},\cdots, \vec{u}^{(m)}\leftarrow R$, $\vec{s}\leftarrow \cHW_{R,t}^{c-1}$, and $\vec{e}^{(1)},\cdots, \vec{e}^{(m)}\leftarrow \cHW_{R,t}$. 

    When we only consider $m=1$, each $R^c$-$\LPN$ instance $ \ipd{\vec{a}}{\vec{s}}+\vec{e}$ can be restated as $\ipd{\vec{a'}}{\vec{e'}}$ where $\vec{a'}=1||\vec{a}$ and $\vec{e'}\leftarrow \cHW_{R,t}^c$. 
\end{definition}

The PCG protocol in \cite{cryptoeprint:2022/1035} generates seed for the OLE correlation $(x_0,x_1,z_0,z_1)\in R^4$ such that $x_0+x_1 = z_0\cdot z_1$. The idea is to first set $z_b = \ipd{\vec{a}}{\vec{e_b}}$ (an $R^c$-$\LPN$ instance with public $\vec{a}$ and $\vec{e_b}\leftarrow \cHW_{R,t}^c$). Basing on the fact that $\ipd{\vec{a}}{ \vec{e_0}}\cdot \ipd{\vec{a}}{\vec{e_1}} = \ipd{\vec{a}\otimes \vec{a}}{\vec{e_0}\otimes \vec{e_1}}$, the next step is to additively share the tensor product $\vec{e_1}\otimes \vec{e_1}$ and each party can compute an additive share of $z_0\cdot z_1$. Note that the tensor product $\vec{e_0}\otimes\vec{e_1}$ consists of $c^2$ entries, each being an deg-$2N$ polynomial with at most $t^2$ nonzero coefficients. Therefore it can be shared by invoking $\DMPF_{t^2, 2N, \mathbb{Z}_p}$ for $c^2$ times.

One can compute the seed size and expanding time of this PCG protocol as follows: 
\begin{itemize}
    \item The seed size is $ct(\log N+\log p)$ bits for specifying $\vec{e_b}$ plus the $c^2\times $keysize of $\DMPF$. 
    \item The expanding time is $c^2N$ multiplications in $R$ plus $c^2\times$full-domain evaluation time of $\DMPF$. 
\end{itemize}

\begin{remark}\label{rem:use_reducible_ring}
    Note that the above PCG protocol generates seed for OLE correlation over ring $R$. One can immediately convert an OLE correlation over ring $R$ to $N$ OLE correlations over $\ZZ_p$ if the polynomial $F(X)$ splits into $N$ distinct linear factors modulo $p$. Therefore we mostly consider reducible $F$ of such form. 
\end{remark}

A previous optimization is to substitute $\cHW_{R,t}$ with regular weight-$t$ polynomials denoted as regular-$\cHW_{R,t}$. Each regular weight-$t$ polynomial $e$ contains exactly one nonzero coefficient $e_j$ in the range of degree $[j\cdot (N/t), (j+1)\cdot (N/t)-1]$ for $j=0,\cdots t-1$. When multiplying two regular weight-$t$ polynomials $e$ and $f$, $e_i\cdot f_j$ contributes to a coefficient in the range of degree $[(i+j)\cdot (2N/t), (i+j+2)\cdot (2N/t)-2]$. Therefore the deg-$2N$ polynomial $e\cdot f$ can be shared by invoking $\{\DMPF_{k, 2N/t, \mathbb{Z}_p}\}_{k=1,2,\cdots,t-1,t,t-1,\cdots, 2,1}$, which cuts down the domain size compared to the original design. 

The previous literature uses sum of DPFs to achieve DMPF in either the original design with nonregular noise or the optimized design with regular noise. It indicates using batch code to achieve DMPF as another optimization but not in the clear. We'll analyze the cost of this PCG protocol under the following settings:
\begin{itemize}
    \item[(1)]with regular noise and each multiplication of sparse polynomials is shared by 2 sets of $\{\DMPF_{k, 2N/t, \mathbb{Z}_p}\}_{1\le k\le t-1}$ and $\DMPF_{t, 2N/t, \mathbb{Z}_p}$;
    \item[(2)]with nonregular noise and each multiplication of sparse polynomials is shared by $\DMPF_{t^2, 2N, \mathbb{Z}_p}$. 
\end{itemize}
We'll instantiate $\DMPF$ in different ways as listed in \cref{tab:formulas_DMPF_comparison}. The costs of PCG protocols under different settings are listed in \cref{tab:LPN_error_distribution}. 
\begin{table*}
    \renewcommand\arraystretch{1.5}
    \caption{Seed size and expanding time of PCG protocols for the same $(\lambda,N, c, t)$ with different choices of noise distributions in module-LPN assumption, and with different $\DMPF$ instantiations. We use \cref{con:OKVS_sparse_matrix} as an instantiation of OKVS. The seed size is represented by total $\DMPF$ share size and the expanding time is represented by total $\DMPF.\FullEval$ time. The PRG evaluations in the first $\log N$ layers and in the convert layer are both regarded as the same PRG. $e$ in the second row represents the expansion parameter for PBC, and $e'$ in the last row represents the expansion parameter for OKVS. }
	\label{tab:LPN_error_distribution}
		\begin{tabular}{cccc}
            \toprule
			$\DMPF$ instantiation & Noise type & Total share size & Total $\FullEval$ time \textcolor{red}{(only listed PRG and $\OKVS$)} \\
            \midrule

            \multirow{2}{*}{Sum of DPFs} & regular & $c^2t^2\lambda\log(2N/t)+c^2t^2\log p$ & $4c^2tN\times$PRG \\
            %\cline{2-4}
             & nonregular & $c^2t^2\lambda\log(2N)+c^2t^2\log p$ & $4c^2t^2N\times$PRG\\
             \cline{1-4}
            \multirow{2}{*}{Batch-code DMPF} & regular & $ec^2t^2\lambda\log(\frac{wN}{et})+ec^2t^2\log p$ & $8c^2wN\times$PRG \\
            %\cline{2-4}
            & nonregular & $ec^2t^2\lambda\log(\frac{2wN}{et^2})+ec^2t^2\log p$ & $4c^2wN\times$PRG\\
            \cline{1-4}

            \multirow{2}{*}{Big-state DMPF} & regular & $c^2t^2(\lambda+\frac{4}{3}t)\log (2N)+c^2t^2\log p$ & $8c^2N\times$PRG$^*$\footnote{The PRG used in big-state DMPF maps from $\{0,1\}^\lambda$ to $\{0,1\}^{2\lambda+2t}$ whose computation time should grow with $t$. } \\
            %\cline{2-4}
            & nonregular & $c^2t^2(\lambda+2t)\log (2N)+c^2t^2\log p$ & $4c^2N\times$PRG$^*$ \\
            \cline{1-4}

            \multirow{2}{*}{OKVS-based DMPF} & regular & $e'c^2t^2\lambda\log(2N/t)+e'c^2t^2\log p$ & $8c^2N\times$PRG+$8c^2N\times\OKVS.\Decode$  \\
            %\cline{2-4}
            & nonregular & $e'c^2t^2\lambda\log(2N)+e'c^2t^2\log p$ & $4c^2N\times$PRG+$4c^2N\times\OKVS.\Decode$\\
            \bottomrule
		\end{tabular}
\end{table*}

\Yaxin{One caveat: can batch-code / OKVS-based DMPF fit into the regular design, while it requires shares of $1,2,3$-point functions?}

From \cref{tab:LPN_error_distribution} we can see that if we allow small blowup of the seed size of PCG, then we can gain much faster seed expansion by using nonregular noise distribution and either batch-code DMPF or big-state DMPF or OKVS-based DMPF. 

\paragraph{Comparing the entropy of regular and nonregular noise.}Moreover, let's consider using the entropy of the noise distribution as the security parameter (which means that we consider the adversary's attack being randomly guessing the secret). Since the entropy of the nonregular noise distribution $\cHW_{R_1,t_1}$ is $\log(\frac{N_1^{t_1}}{t_1^{t_1}})$ while the entropy of the regular noise distribution regular-$\cHW_{R_2,t_2}$ is $\log(\frac{N_2^{t_2}}{t_2!})$, to settle for the same level of security we only need $t_1=t_2$ and $N_1 = N_2/\mathrm{e}$ where $\mathrm{e}$ is the natural logarithm. Placing this back to \cref{tab:LPN_error_distribution}, the total $\FullEval$ time (i.e., the seed expanding time of PCG) can have an extra $\times \mathrm{e}$ speedup. 

Next we plug in concrete parameters and evaluate the performance of different $\DMPF$ schemes under different PCG parameter settings. 

Define the number of noisy coordinate $W:=ct$. We set $(\lambda, c, N, W)$ such that the best attack requires at least $2^\lambda$ arithmetic operations over field $\FF_p$ of size approximately $2^{128}$. According to \cite{cryptoeprint:2022/1035}, for $R$ from irreducible $F$, we lowerbound the number of arithmetic operations by $N\cdot (c\cdot \frac{N}{N-1})^W\approx N\cdot c^W$. For $R$ from reducible $F$, we lowerbound the number of arithmetic operations by $2^i\cdot c^{W_i}$ \Yaxin{(to be checked)}, where $i:=\mathop{\arg\min}\limits_{1\le i\le \log N}\left((\frac{c\cdot 2^i}{(c-1)\cdot 2^i-1})^{w_i}\cdot 2^i\right)$ and $W_i:=c(c-1)\cdot 2^i\left(1-(1-\frac{1}{(c-1)2^i})^{W/c}\right)$. \Yaxin{(to be checked) In the end we round $W$ such that $t=W/c$ is an integer. }


\Yaxin{Previous calculation as a reference: } choosing the big-state DMPF for $t<8$ and the OKVS-DMPF for $t\ge 8$ gives at least $\times 2$ acceleration on expand time over other choices with sacrifice on the keysize. There is a tradeoff between the batch-code and OKVS-DMPF in that the OKVS-DMPF always provides a $\sim\times 2$ acceleration on expand time, but a loss in seed size that when $t$ is large it may blow up the seed size to $\sim \times 2$ that of the batch-code-DMPF. 

\subsection{PSI-WCA}
\Yaxin{TBD: 
\begin{itemize}
  \item plug in new DMPF and analyze advantage interval
  \item plug in distributed gen
\end{itemize}}
\Yaxin{Previous calculation as a reference: }A short conclusion is using big-state DMPF for $t<64$ and the OKVS-DMPF for $t\ge 64$ gives at $\sim \times 2$ faster Eval() time and faster Gen() time compared to the naive and batch-code construction. The keysize ($\propto$ communication complexity) of our choice is usually smaller than the batch-code DMPF and slightly larger than the naive construction. 
\subsection{Security analysis}
\subsection{Heavy-hitters}
private heavy-hitter\\
or parallel ORAM?