\section{Applications}
\Yaxin{This section is highly incomplete... Each subsection contains some to do list and I'll do more research. } 

For convenience of discussion DMPF applications, we use $\DMPF_{t, N, \GG}$ to denote a DMPF scheme for $t$-point functions with domain $[N]$ and output group $\GG$. 

\begin{table*}
  \caption{Concrete applications of DMPF. }
  \label{tab:app_parameters}
	\begin{tabular}{ccc}
    \toprule
		Concrete application &\makecell{Cost in terms of DMPF\\per correlation/execution}& Typical DMPF parameters \\
    \midrule
		PCG for OLE from Ring-LPN &\makecell{seedsize $\propto$ DMPF.$keysize$\\expand time $\propto$ DMPF.$FullEval()$} & \makecell{$t = 5^2, 16^2, 76^2$\\$N = 2^{20}$}  \\
		PSI-WCA & \makecell{communication $\propto$ DMPF.$keysize$\\client computation $\propto$ DMPF.$Gen()$\\server computation $\propto$ DMPF.$Eval()$} & \makecell{$t = $any\\$N = 2^{128}$}\\
    \bottomrule
	\end{tabular}
\end{table*}

\subsection{PCG for OLE from Ring-$\LPN$}

We begin by briefly introducing the protocol of PCG for OLE from Ring-$\LPN$ assumption, proposed in \cite{cryptoeprint:2022/1035}. 

\paragraph{The PCG protocol for OLE correlation.}The hardness assumption we will make use of is a variant of Ring-$\LPN$, called module-$\LPN$ assumption. 
\begin{definition}[Module-$\LPN$]\label{def:module-LPN}
    Let $c\ge 2$ be an integer, $R = \ZZ_p[X]/F(X)$ for a prime $p$ and a deg-$N$ polynomial $F(X)\in \ZZ_p[X]$, and $\mathcal{HW}_{R,t}$ be the uniform distribution over \`weight-$t$\' polynomials in $R$ whose degree is less than $N$ and has at most $t$ nonzero coefficients. 
    %(We write $\mathcal{HW}_t$ when $R$ is clear from the context. )
     For $R=R(\lambda)$, $t=t(\lambda)$ and $m=m(\lambda)$, we say that the module-$\LPN$ problem $R^c$-$\LPN$ is hard if for every nonuniform polynomial-time probabilistic distinguisher $\cA$, it holds that 
    \[
        |\Pr[\cA(\{\vec{a}^{(i)}, \ipd{\vec{a}^{(i)}}{\vec{s}}+\vec{e}^{(i)}\}_{i\in [m]})] - \Pr[\cA(\{\vec{a}^{(i)},\vec{u}^{(i)}\}_{i\in [m]})] \le \mathsf{negl}(\lambda)
    \]
    where the probabilities are taken over the randomness of $\cA$, random samples $\vec{a}^{(1)},\cdots, \vec{a}^{(m)}\leftarrow R^{c-1}$, $\vec{u}^{(1)},\cdots, \vec{u}^{(m)}\leftarrow R$, $\vec{s}\leftarrow \cHW_{R,t}^{c-1}$, and $\vec{e}^{(1)},\cdots, \vec{e}^{(m)}\leftarrow \cHW_{R,t}$. 

    When we only consider $m=1$, each $R^c$-$\LPN$ instance $ \ipd{\vec{a}}{\vec{s}}+\vec{e}$ can be restated as $\ipd{\vec{a'}}{\vec{e'}}$ where $\vec{a'}=1||\vec{a}$ and $\vec{e'}\leftarrow \cHW_{R,t}^c$. 
\end{definition}

The PCG protocol in \cite{cryptoeprint:2022/1035} generates seed for the OLE correlation $(x_0,x_1,z_0,z_1)\in R^4$ such that $x_0+x_1 = z_0\cdot z_1$. The idea is to first set $z_b = \ipd{\vec{a}}{\vec{e_b}}$ (an $R^c$-$\LPN$ instance with public $\vec{a}$ and $\vec{e_b}\leftarrow \cHW_{R,t}^c$). Basing on the fact that $\ipd{\vec{a}}{ \vec{e_0}}\cdot \ipd{\vec{a}}{\vec{e_1}} = \ipd{\vec{a}\otimes \vec{a}}{\vec{e_0}\otimes \vec{e_1}}$, the next step is to additively share the tensor product $\vec{e_1}\otimes \vec{e_1}$ and each party can compute an additive share of $z_0\cdot z_1$. Note that the tensor product $\vec{e_0}\otimes\vec{e_1}$ consists of $c^2$ entries, each being an deg-$2N$ polynomial with at most $t^2$ nonzero coefficients. Therefore it can be shared by invoking $\DMPF_{t^2, 2N, \mathbb{Z}_p}$ for $c^2$ times.

One can compute the seed size and expanding time of this PCG protocol as follows: 
\begin{itemize}
    \item The seed size is $ct(\log N+\log p)$ bits for specifying $\vec{e_b}$ plus the $c^2\times $keysize of $\DMPF$. 
    \item The expanding time is $c^2N$ multiplications in $R$ plus $c^2\times$full-domain evaluation time of $\DMPF$. 
\end{itemize}

\begin{remark}\label{rem:use_reducible_ring}
    Note that the above PCG protocol generates seed for OLE correlation over ring $R$. One can immediately convert an OLE correlation over ring $R$ to $N$ OLE correlations over $\ZZ_p$ if the polynomial $F(X)$ splits into $N$ distinct linear factors modulo $p$. Therefore we mostly consider reducible $F$ of such form. 
\end{remark}

A previous optimization is to substitute $\cHW_{R,t}$ with regular weight-$t$ polynomials denoted as regular-$\cHW_{R,t}$. Each regular weight-$t$ polynomial $e$ contains exactly one nonzero coefficient $e_j$ in the range of degree $[j\cdot (N/t), (j+1)\cdot (N/t)-1]$ for $j=0,\cdots t-1$. When multiplying two regular weight-$t$ polynomials $e$ and $f$, $e_i\cdot f_j$ contributes to a coefficient in the range of degree $[(i+j)\cdot (2N/t), (i+j+2)\cdot (2N/t)-2]$. Therefore the deg-$2N$ polynomial $e\cdot f$ can be shared by invoking $\{\DMPF_{k, 2N/t, \mathbb{Z}_p}\}_{k=1,2,\cdots,t-1,t,t-1,\cdots, 2,1}$, which cuts down the domain size compared to the original design. 

The previous literature uses sum of DPFs to achieve DMPF in either the original design with nonregular noise or the optimized design with regular noise. It indicates using batch code to achieve DMPF as another optimization but not in the clear. We'll analyze the cost of this PCG protocol under the following settings:
\begin{itemize}
    \item[(1)]with regular noise and each multiplication of sparse polynomials is shared by 2 sets of $\{\DMPF_{k, 2N/t, \mathbb{Z}_p}\}_{1\le k\le t-1}$ and $\DMPF_{t, 2N/t, \mathbb{Z}_p}$;
    \item[(2)]with nonregular noise and each multiplication of sparse polynomials is shared by $\DMPF_{t^2, 2N, \mathbb{Z}_p}$. 
\end{itemize}
We'll instantiate $\DMPF$ in different ways as listed in \cref{tab:formulas_DMPF_comparison}. The costs of PCG protocols under different settings are listed in \cref{tab:PCG_plug_in_formula}. 
\begin{table*}
    \renewcommand\arraystretch{1.5}
    \begin{threeparttable}
    \caption{Seed size and expanding time of PCG protocols for the same $(\lambda,N, c, t)$ with different choices of noise distributions in module-LPN assumption, and with different $\DMPF$ instantiations. We use \cref{con:OKVS_sparse_matrix} as an instantiation of OKVS. The seed size is represented by total $\DMPF$ share size and the expanding time is represented by total $\DMPF.\FullEval$ time. The PRG evaluations in the first $\log N$ layers and in the convert layer are both regarded as the same PRG. $e$ in the second row represents the expansion parameter for PBC, and $e'$ in the last row represents the expansion parameter for OKVS. }
	\label{tab:PCG_plug_in_formula}
		\begin{tabular}{cccc}
            \toprule
			$\DMPF$ instantiation & Noise type & Total share size & Total $\FullEval$ time \textcolor{red}{(only listed PRG and $\OKVS$)} \\
            \midrule

            \multirow{2}{*}{Sum of DPFs} & regular & $c^2t^2\lambda\log(2N/t)+c^2t^2\log p$ & $4c^2tN\times$PRG \\
            %\cline{2-4}
             & nonregular & $c^2t^2\lambda\log(2N)+c^2t^2\log p$ & $4c^2t^2N\times$PRG\\
             \cline{1-4}
            \multirow{2}{*}{Batch-code DMPF} & regular & $ec^2t^2\lambda\log(\frac{wN}{et})+ec^2t^2\log p$ & $8c^2wN\times$PRG \\
            %\cline{2-4}
            & nonregular & $ec^2t^2\lambda\log(\frac{2wN}{et^2})+ec^2t^2\log p$ & $4c^2wN\times$PRG\\
            \cline{1-4}

            \multirow{2}{*}{Big-state DMPF} & regular & $c^2t^2(\lambda+\frac{4}{3}t)\log (2N)+c^2t^2\log p$ & $8c^2N\times$PRG$^*$\tnote{1} \\
            %\cline{2-4}
            & nonregular & $c^2t^2(\lambda+2t)\log (2N)+c^2t^2\log p$ & $4c^2N\times$PRG$^*$ \\
            \cline{1-4}

            \multirow{2}{*}{OKVS-based DMPF} & regular & $e'c^2t^2\lambda\log(2N/t)+e'c^2t^2\log p$ & $8c^2N\times$PRG+$8c^2N\times\OKVS.\Decode$  \\
            %\cline{2-4}
            & nonregular & $e'c^2t^2\lambda\log(2N)+e'c^2t^2\log p$ & $4c^2N\times$PRG+$4c^2N\times\OKVS.\Decode$\\
            \bottomrule
		\end{tabular}
    \begin{tablenotes}
      \item [1] The PRG used in big-state DMPF maps from $\{0,1\}^\lambda$ to $\{0,1\}^{2\lambda+2t^2}$ whose computation time should grow with $t^2$. 
    \end{tablenotes}
  \end{threeparttable}
\end{table*}

\Yaxin{One caveat: can batch-code / OKVS-based DMPF fit into the regular design, while it requires shares of $1,2,3$-point functions?}

From \cref{tab:PCG_plug_in_formula} we can see that if we allow small blowup of the seed size of PCG, then we can gain much faster seed expansion by using nonregular noise distribution and either batch-code DMPF or big-state DMPF or OKVS-based DMPF. 

\paragraph{Comparing the entropy of regular and nonregular noise.}Moreover, let's consider using the entropy of the noise distribution as the security parameter (which means that we consider the adversary's attack being randomly guessing the secret). Since the entropy of the nonregular noise distribution $\cHW_{R_1,t_1}$ is $\log(\frac{N_1^{t_1}}{t_1^{t_1}})$ while the entropy of the regular noise distribution regular-$\cHW_{R_2,t_2}$ is $\log(\frac{N_2^{t_2}}{t_2!})$, to settle for the same level of security we only need $t_1=t_2$ and $N_1 = N_2/\mathrm{e}$ where $\mathrm{e}$ is the natural logarithm. Placing this back to \cref{tab:PCG_plug_in_formula}, the total $\FullEval$ time (i.e., the seed expanding time of PCG) can have an extra $\times \mathrm{e}$ speedup. 

\Yaxin{Double check i the cost of practical attacks against $R^c$-$\LPN$ scales with entropy. }

Next we plug in concrete parameters and evaluate the performance of different $\DMPF$ schemes under different PCG parameter settings. 

Define the number of noisy coordinate $W:=ct$. We set $(\lambda, c, N, W)$ such that the best attack requires at least $2^\lambda$ arithmetic operations over field $\FF_p$ of size approximately $2^{128}$. According to \cite{cryptoeprint:2022/1035}, for $R$ from an irreducible $F$, we lowerbound the number of arithmetic operations by $N\cdot (c\cdot \frac{N}{N-1})^W\approx N\cdot c^W$. \Yaxin{Check \cite{cryptoeprint:2022/712} for latest update about this cost. } For $R$ from a reducible $F$, we lowerbound the number of arithmetic operations by $2^i\cdot c^{W_i}$ , where $i:=\mathop{\arg\min}\limits_{1\le i\le \log N}\left(2^i\cdot c^{W_i}\right)$ and $W_i:=W-cn+(c(n-1)+W)\cdot \left(1-\frac{1}{n}\right)^{W/c-1}$. In the end we round $W$ such that $t=W/c$ is an integer. 


\Yaxin{Previous calculation as a reference: } choosing the big-state DMPF for $t<8$ and the OKVS-DMPF for $t\ge 8$ gives at least $\times 2$ acceleration on expand time over other choices with sacrifice on the keysize. There is a tradeoff between the batch-code and OKVS-DMPF in that the OKVS-DMPF always provides a $\sim\times 2$ acceleration on expand time, but a loss in seed size that when $t$ is large it may blow up the seed size to $\sim \times 2$ that of the batch-code-DMPF. 

\subsection{Unbalanced PSI-WCA}
A private set intersection (PSI) protocol allows two parties with input $X$, $Y$ being two sets to learn about their intersection $X\cap Y$ without revealing additional information of $X$ or $Y$. We denote by PSI-WCA (weighted cardinality) a variant of PSI that computes the weighted cardinality of elements in $X\cap Y$ where the weights are determined by a pre-fixed function $w(\cdot)$. 

We will be interested in \emph{unbalanced} PSI-WCA where $|X|\gg |Y|$ and the output should be received by the party holding $Y$. In this problem we call the party holding $X$ as the server, and the party holding $Y$ as the client. If further the big set $X$ is held by two non-colluding servers, then such an unbalanced PSI-WCA protocol can be constructed from DMPF, as suggested in \cite{cryptoeprint:2020/1599}: 
\begin{itemize}
  \item The client invokes $\DMPF.\Gen(1^\lambda, \hat{f}_{Y,w(Y)})\rightarrow (k_0,k_1)$, where $w(Y)$ is the set of weights of elements in $Y$. Then the client send $k_0$ to server 0 and $k_1$ to server 1. 
  \item Server $b$ computes $s_b=\sum_{x\in X}\DMPF.\Eval_b(1^\lambda, k_b,x)$ and send it back to the client. 
  \item The client computes $s_0+s_1$, which will be the weighted cardinality of $X\cap Y$. 
\end{itemize}
One caveat is that this protocol reveals information about $Y$ that is leaked by $\DMPF$. Plugging in any $\DMPF$ instantiations we have mentioned, the size of $|Y|$ will be leaked to the servers. 

The cost of our unbalanced PSI-WCA can be computed as follows: 
\begin{itemize}
  \item The communication cost equals the keysize of $\DMPF$. 
  \item The client computation time equals the key generation time of $\DMPF$. 
  \item The server computation time equals $|X|\times$the evaluation time of $\DMPF$. 
\end{itemize}

We'll instantiate $\DMPF$ in different ways as listed in \cref{tab:formulas_DMPF_comparison}. As suggested in \cite{cryptoeprint:2020/1599}, we take an infeasibly large domain for the sets $X$ and $Y$ to locate, whose size is $N = 2^{128}$. The set sizes $|X|$ and $|Y|$ can vary depending on application scenarios. Since $|Y|$ is the crucial factor that distinguishes different $\DMPF$ instantiations, we will only consider the change of $|Y|$. The costs of PSI-WCA protocols under different settings of $|Y|$ are listed in \cref{tab:PSI_plug_in_formula}. 


\begin{table*}
  \renewcommand\arraystretch{1.5}
  \begin{threeparttable}
  \caption{Communication cost, client and server computation time of the PSI-WCA protocol for domain size $N = 2^{128}$, weight group $\GG$, and  different choices of client's set size $|Y|$. We use \cref{con:OKVS_sparse_matrix} as an instantiation of OKVS. The PRG evaluations in the first $\log N$ layers and in the convert layer are both regarded as the same PRG. $e$ in the second row represents the expansion parameter for PBC, and $e'$ in the last row represents the expansion parameter for OKVS. }
\label{tab:PSI_plug_in_formula}
  \begin{tabular}{cccc}
          \toprule
    $\DMPF$ instantiation & Communication cost & Client computation time & Server computation time \\
          \midrule

          Sum of DPFs & $|Y|\lambda\log N+|Y|\log|\GG|$ & $2|Y|\log N\times $PRG & $|X|\cdot |Y|\log N\times $PRG\\

          Batch-code DMPF & $e|Y|\lambda\log(\frac{wN}{e|Y|})+e|Y|\log|\GG|$ & $2e|Y|\log(\frac{wN}{e|Y|})\times$PRG & $w|X|\log(\frac{wN}{e|Y|})\times$PRG\\

          Big-state DMPF & $|Y|(\lambda+2|Y|)\log N+|Y|\log|\GG|$ & $2|Y|\log N\times $PRG$^*$\tnote{1} & $|X|\log N \times$PRG$^*$\\

          OKVS-based DMPF& $e'|Y|\log N +e'|Y|\log|\GG|$ & $2|Y|\log N\times$PRG+$\log N\times \OKVS.\Encode$ & $|X|(\log N\times$PRG+$\log N\times \OKVS.\Decode)$\\
          \bottomrule
  \end{tabular}
  \begin{tablenotes}
    \item [1] The PRG used in big-state DMPF maps from $\{0,1\}^\lambda$ to $\{0,1\}^{2\lambda+2|Y|}$ whose computation time should grow with $|Y|$.
  \end{tablenotes}
\end{threeparttable}
\end{table*}



\Yaxin{Previous calculation as a reference: }A short conclusion is using big-state DMPF for $t<64$ and the OKVS-DMPF for $t\ge 64$ gives at $\sim \times 2$ faster Eval() time and faster Gen() time compared to the naive and batch-code construction. The keysize ($\propto$ communication complexity) of our choice is usually smaller than the batch-code DMPF and slightly larger than the naive construction. 
\subsection{Security analysis}
\subsection{Heavy-hitters}
private heavy-hitter\\
or parallel ORAM?