\section{Preliminaries}
\subsection{Basic Notations}
Throughout the paper, we use $[n]$ to denote the ordered list of numbers $1,2,\dots n$. For a list $L$ of length $l$, we use $L[k] (1\le k\le l)$ to denote the $k$th entry of this list, and we use $L[i\dots j]$ to denote the list $(L[i],L[i+1],\dots,L[j])$. If the entries of $L$ are in the domain of a function $f$, define $f(L) := (f(x))_{x\in L}$ to be the list obtained by entry-wise applying $f$ to $L$. When $b\in\{0,1\}$ is a bit, we use $\bar{b}$ to denote $1-b$. We use $\llbracket X\rrbracket_0$ and $\llbracket X\rrbracket_1$ to denote the random additive shares of an entity $X$ whenever it is applicable. 

\paragraph{Point and multi-point functions. }Given a domain size $N$ and Abelian group $\GG$, a \emph{point function} $f_{\alpha,\beta}:[N]\rightarrow\GG$ for $\alpha\in[N]$ and $\beta\in\GG$ evaluates to $\beta$ on input $\alpha$ and to $0\in\GG$ on all other inputs. We denote by $\hat{f}_{\alpha,\beta}=(N,\hat{\GG},\alpha,\beta)$ the representation of such a point function, where $\hat{\GG}$ denotes the description of the group $\GG$. A \emph{$t$-point function} $f_{A,B}:[N]\rightarrow \GG$ for $A=\{\alpha_1,\cdots\alpha_t\}\subset N$ listed in ascending order and $B=(\beta_1,\cdots,\beta_t)\in \GG^t$ evaluates to $\beta_i$ on input $\alpha_i$ for $1\le i\le t$ and to $0$ on all other inputs. Let $\hat{f}_{A,B}(N,\hat{\GG},t,A,B)$ denote the representation of such a $t$-point function. Call the collection of all $t$-point functions for all $t$ \emph{multi-point functions}. 

\subsection{Distributed Multi-Point Functions}

We begin by defining the notion of distributed multi-point functions (DMPF), which is a generalization of distributed point function (DPF \cite{10.1007/978-3-662-46803-6_12,BoyGilIsh16}).

\iffalse
\begin{definition}[DPF \cite{EC:GilIsh14,BoyGilIsh16}]\label{def:dpf}
A 
%$t$-private $m$-server 
(2-party)
\emph{distributed point function (DPF)}
%, or $(m,t)$-DPF for short, 
is a triple of algorithms %$\Pi=(\Gen,\Eval_0,\ldots,\Eval_{m-1})$ 
$\Pi=(\Gen,\Eval_0,\Eval_1)$
with the following syntax: 
\begin{itemize}
    \item $\Gen(1^\lambda,\hat{f}_{\alpha,\beta})\rightarrow (k_0,k_1)$: On input security parameter $\lambda\in\NN$ and point function description $\hat{f}_{\alpha,\beta}=(N,\hat{\GG},\alpha,\beta)$, the (randomized) key generation algorithm $\Gen$ returns a pair of keys $k_0,k_1\in\{0,1\}^*$. 
    We assume that $N$ and $\GG$ are determined by each key.
    \item $\Eval_b(k_b,x)\rightarrow y_b$: On input key $k_b\in\{0,1\}^*$ and input $x\in[N]$ the (deterministic) evaluation algorithm of server $b$, $\Eval_b$, returns 
    %a group element 
    $y_b\in\GG$.
\end{itemize}
%The algorithms $\Pi=(\Gen,\Eval_0,\ldots,\Eval_{m-1})$ should 
We require that $\Pi$ satisfies the following requirements:
\begin{itemize}
    \item \textbf{Correctness:} For every $\lambda$, $\hat{f}=\hat{f}_{\alpha,\beta}=(N,\hat{\GG},\alpha,\beta)$ such that $\beta\in\GG$, and $x\in[N]$,   
    $$\Pr\left[(k_0,k_1)\leftarrow\Gen(1^\lambda,\hat{f}), \sum_{b=0}^{1}\Eval_b(k_b,x)=f_{\alpha,\beta}(x)\right]=1$$
    \item \textbf{Security:} Consider the following semantic security challenge experiment for corrupted server $b\in\{0,1\}$:
    \begin{enumerate}
        \item The adversary produces two point function descriptions $(\hat{f}^0=(N,\hat\GG,\alpha_0,\beta_0),\hat{f}^1=(N,\hat\GG,\alpha_1,\beta_1))\leftarrow\mathcal{A}(1^\lambda)$, where $\alpha_b\in[N]$ and $\beta_b\in\GG$.
        \item The challenger samples $b\gets\{0,1\}$ and $(k_0,k_1)\leftarrow\Gen(1^\lambda,\hat{f}^b)$.
        \item The adversary outputs a guess $b'\leftarrow\mathcal{A}(k_b)$.
    \end{enumerate}
    Denote by $\Adv(1^\lambda,\mathcal{A},i)=\Pr[b=b']-1/2$ the advantage of $\mathcal{A}$ in guessing $b$ in the above experiment. For every non-uniform polynomial time adversary $\mathcal{A}$ there exists a negligible function $\nu$ such that $\Adv(1^\lambda,\mathcal{A},i) \le \nu(\lambda)$ for all $\lambda \in \NN$.
%    For circuit size bound $S=S(\lambda)$ and advantage bound $\epsilon(\lambda)$, we say that $\Pi$ is $(S,\epsilon)$-secure if for all $i\in\{0,1\}$ and all non-uniform adversaries $\mathcal{A}$ of size $S(\lambda)$ and sufficiently large $\lambda$, we have $\Adv(1^\lambda,\mathcal{A},i)\leq\epsilon(\lambda)$. We say that $\Pi$ is:
%    \begin{itemize}
%        \item \emph{Computationally $\epsilon$-secure} if it is $(S,\epsilon)$-secure for all polynomials $S$.
%        \item \emph{Computationally secure} if it is $(S,1/S)$-secure for all polynomials $S$.
%        %\item \emph{Statistically $\epsilon$-secure} if it is $(S,\epsilon)$-secure for all $S$.
%        %\item \emph{Perfectly secure} if it is statistically $0$-secure.
%    \end{itemize}
\end{itemize}
%If the security threshold $t$ is unspecified, we assume it is $t=1$.
\end{definition}\fi

\begin{definition}[DMPF \cite{cryptoeprint:2019/273,cryptoeprint:2021/580,BoyGilIsh16}]\label{def:dmpf}
  A 
  %$t$-private $m$-server 
  (2-party)
  \emph{distributed multi-point function (DMPF)}
  %, or $(m,t)$-DPF for short, 
  is a triple of algorithms %$\Pi=(\Gen,\Eval_0,\ldots,\Eval_{m-1})$ 
  $\Pi=(\Gen,\Eval_0,\Eval_1)$
  with the following syntax: 
  \begin{enumerate}[itemsep = 5pt]
      \item $\Gen(1^\lambda,\hat{f}_{A,B})\rightarrow (k_0,k_1)$: On input security parameter $\lambda\in\NN$ and point function description $\hat{f}_{A,B}=(N,\hat{\GG},t,A,B)$, the (randomized) key generation algorithm $\Gen$ returns a pair of keys $k_0,k_1\in\{0,1\}^*$. %\Yaxin{On Matan's behalf: same comment as well. Maybe $|k_i|=\poly(\lambda,t)$. }
      \item $\Eval_b(1^\lambda, k_b,x)\rightarrow y_b$: On input key $k_b\in\{0,1\}^*$ and input $x\in[N]$ the (deterministic) evaluation algorithm of server $b$, $\Eval_b$ returns $y_b\in\GG$.
      \item $\FullEval_b(1^\lambda, k_b)$: Returns $\{\Eval_b(1^\lambda,k_b,x)\}_{x\in [N]}$. 
  \end{enumerate}
  We require $\Pi$ to satisfy the following requirements:
  \begin{itemize}
      \item[] \textbf{Correctness:} For every $\lambda$, $\hat{f}_{A,B}=(N,\hat{\GG},t,A,B)$ such that $B\in\GG^t$, and $x\in[N]$
      \[
          \Pr\left[\begin{array}{c}(k_0,k_1)\leftarrow\Gen(1^\lambda,\hat{f}), \\\Eval_0(k_0,x)+\Eval_1(k_1,x)=f_{A,B}(x)\end{array}\right]=1
      \]

      \item[] \textbf{Security: }For any corrupted party $b = 0,1$, there exists a p.p.t. simulator $\sf Sim$ such that for every $\hat{f} = \hat{f}_{A,B} = (N,\hat{\GG},t,A,B)$, the outputs of the following experiments $\sf Real$ and $\sf Ideal$ are computationally indistinguishable: 
      \begin{itemize}
          \item[-]${\sf Real}:\,(k_0,k_1)\gets \Gen(1^\lambda, \hat{f})$, output $k_b$. 
          \item[-]$\sf Ideal:$ Output ${\sf Sim}(1^\lambda, N,\hat{\GG},t)$. 
      \end{itemize}
  \end{itemize}
  \end{definition}

\subsection{Previous Constructions}

The distributed point function (DPF \cite{10.1007/978-3-662-46803-6_12,BoyGilIsh16}) is a special case of DMPF where $t=1$. 
One can construct a DMPF scheme for $t$-point functions by simply summing $t$ DPFs, which is the most widely used construction.  
\begin{construction}[Na\"ive DMPF]\label{con:naive_DMPF}
  Given a DPF scheme $\DPF$ for domain of size $N$ and output group $\GG$, we can construct a DMPF scheme for $t$-point functions with domain size $N$ and output group $\GG$ as follows: 
  \begin{enumerate}[itemsep = 5pt]
    \item $\Gen(1^\lambda, \hat{f}_{A, B})\rightarrow (k_0, k_1)$: For $1\le i\le t$, invoke $\DPF.\Gen(1^\lambda, \hat{f}_{A[i], B[i]})\rightarrow (k_0^i, k_1^i)$. Set $(k_0, k_1) = (\{k_0^i\}_{i\in [t]}, \{k_1^i\}_{i\in [t]})$. 
    \item $\Eval_b(k_b, x)\rightarrow \sum_{i\in [t]}\DPF.\Eval_b(k_b^i, x)$. 
    \item $\FullEval_b(k_b)\rightarrow  \sum_{i\in [t]}\DPF.\FullEval_b(k_b^i, x)$. 
  \end{enumerate}
\end{construction}
When the DPF scheme is correct and secure, the na\"ive DMPF is also correct and secure. We note that the keysize and running time of $\Gen$, $\Eval$ and $\FullEval$ of the na\"ive DMPF equals $t\times $ those of DPF, serving as our baseline for comparison. 

Another known construction of DMPF bases on probabilistic (combinatorial) batch codes (PBC) with appropriate parameters, which has been discussed in previous literature \cite{cryptoeprint:2019/273,cryptoeprint:2019/1084,cryptoeprint:2021/580,foleage} with PBC instantiated by cuckoo hashing. PBC (\cite{cryptoeprint:2017/1142,10.1145/1007352.1007396,cryptoeprint:2022/1455}) is a relaxed variant of combinatorial batch codes permitting small decoding errors with parameters $(N,M,t,m,\epsilon)$, which encodes the domain $[N]$ to $m$ codewords in $[N]^*$ of total length $M$, such that for any set $I\subseteq [N]$ of size at most $t$, there is a procedure (referred to as ${\sf Schedule}(I)$) that with probability at least $1-\epsilon$, identifies $|I|$ entries across the $m$ codewords covering $I$, ensuring that at most one entry is selected from each codeword. For clarity of discussion, we refer to the procedure of finding all occurrences of an element $k\in[N]$ as ${\sf Position}(k)$. We provide the formal definitions of PBC in Appendix~\ref{sec:batch_codes}, due to page limit.  

To generate keys for distributing a $t$-point function $f_{A,B}$ with domain $N$, one can first encode the domain to $m$ codewords and invoke ${\sf Schedule}(A)$ to identify one entry in each of the $m$ codewords, and then generate a DPF key for each codeword, as described below: 

\begin{construction}[PBC-based DMPF]\label{con:DMPF_PBC}
    Given a family $\{\DPF_{N',\GG}\}_{N'}$ for any domain of size $N'\le N$ and output group $\GG$, and an $(N,M,t,m,\epsilon)$-$\PBC$, we can construct a $\DMPF$ for $t$-point functions with domain size $N$ and output group $\GG$ as follows: 
  \begin{enumerate}[itemsep=5pt]
    \item $\Gen(1^\lambda, \hat{f}_{A,B})\rightarrow (k_0,k_1)$: Let $\PBC$ encode $[N]$ to codewords $C_1,\dots,C_m$. Invoke $\PBC.\Schedule(A)$ to get the ordered list of entries $\left(C_{i_k}[j_k]\right)_{k\in[t]}$.
    %If $\PBC.\Schedule$ fails then run it again with a fresh public randomness. 
    
    For all $1\le k\le t$ For $1\le i\le m$, let $f_i:[|C_i|]\rightarrow \GG$ be the following: 
    \begin{itemize}
    \item If there is exactly one $k\in[t]$ that  $i_k = i$, then set $f_i$ to be the point function that outputs $B[k]$ on $j_k$ and $0_\GG$ elsewhere. 
    \item Otherwise set $f_i$ to be the all-zero function. 
    \end{itemize}
    For $1\le i\le m$, invoke $\DPF.\Gen(1^\lambda, \hat{f}_i)\rightarrow (k_0^i,k_1^i)$. Set $(k_0,k_1)=(\{k_0^i\}_{i\in [m]}, \{k_1^i\}_{i\in [m]})$. 
    \item $\Eval_b(k_b,x)\rightarrow y_b$: Invoke $\PBC.\Position(x)$ to obtain all occurrences of $x$ in codewords $C_{i_1}[j_1],\dots,C_{i_s}[j_s]$. Compute $y_b=\sum_{l=1}^s\DPF.\Eval_b(k_b^{i_l},j_l)$. 
    \item $\FullEval_b(k_b)\rightarrow Y_b$: For $1\le i\le m$, compute $Y_b^i = \DPF.\FullEval_b(k_b^i)$. For all $x\in [N]$, invoke $\PBC.\Position(x)\rightarrow C_{i_1}[j_1],\dots,C_{i_s}[j_s]$, and set $Y_b[x]\gets \sum_{l=1}^sY_b^{i_l}[j_l]$. 
  \end{enumerate}
\end{construction}
The scheme is correct with at least $1-\epsilon$ probability. In turn, the PBC-based DMPF have keysize and running time of $\Gen$, $\Eval$ and $\FullEval$ being the total cost of the $\DPF$'s, plus extra PBC operations. 

\subsection{Oblivious Key-Value Stores}\label{sec:prelim_okvs}
We introduce the notion of Oblivious key-value stores (OKVS) which can be used to construct DMPF. OKVS was proposed as a primitive for private set intersection (PSI) protocols \cite{cryptoeprint:2021/883}, and improved by a series of works \cite{cryptoeprint:2022/320,cryptoeprint:2023/903}. 
\begin{definition}[Oblivious Key-Value Stores (OKVS)\cite{cryptoeprint:2021/883,cryptoeprint:2022/320,cryptoeprint:2023/903}]\label{def:OKVS}
  An Oblivious Key-Value Stores scheme is a pair of randomized algorithms $(\Encode_r,\Decode_r)$ with respect to a statistical security parameter $\lambda_{\sf stat}$ and a computational security parameter $\lambda$, a randomness space $\{0,1\}^\kappa$, a key space $\mathcal{K}$, a value space $\mathcal{V}$, input length $t$ and output length $m$. The algorithms are of the following syntax: 
  \begin{enumerate}
    \item $\Encode_r(\{(k_1,v_1),(k_2,v_2),\cdots,(k_t,v_t)\})\rightarrow P$: On input $t$ key-value pairs with distinct keys, the encode algorithm with randomness $r$ in the randomness space outputs an encoding $P\in\mathcal{V}^m\cup\bot$.
    \item $\Decode_r(P,k)\rightarrow v$: On input an encoding from $\mathcal{V}^m$ and a key $k\in\mathcal{K}$, output a value $v$. 
  \end{enumerate}
  We require the scheme to satisfy
  \begin{itemize}[itemsep=5pt]
    \item[]\textbf{Correctness: }For all $S\in(\mathcal{K}\times\mathcal{V})^t$, $\Pr[{r\leftarrow\{0,1\}^\kappa},$ $\Encode_r(S)=\bot]\le \epsilon$. For all $S\in(\mathcal{K}\times \mathcal{V})^t$ and $r\in \{0,1\}^\kappa$ such that $\Encode_r(S)\rightarrow P\not=\bot$, $\Decode_r(P,k)$ outputs $ v$ whenever $(k,v)\in S$. By default we require $\epsilon = 2^{-\lambda_\stat}$.
    \item[] \textbf{Obliviousness: }Given any distinct sets $\{k_1^0,k_2^0,\cdots,k_t^0\}$ and $\{k_1^1,k_2^1,\cdots,k_t^1\}$ that are different, if they are paired with random values then their encodings are computationally indistinguishable, i.e., 
  \begin{align*}
    &\{r, \Encode_r(\{(k_1^0,v_1),\cdots,(k_t^0,v_t)\})\}_{v_1,\cdots,v_t\leftarrow \mathcal{V},r\leftarrow\{0,1\}^\kappa}\\
    \approx_c &\{r, \Encode_r(\{(k_1^1,v_1),\cdots,(k_t^1,v_t)\})\}_{v_1,\cdots,v_t\leftarrow \mathcal{V},r\leftarrow\{0,1\}^\kappa}
  \end{align*}
  If the distinguishing advantage is upperbounded by a negligible function $\epsilon$, then the OKVS scheme is $\epsilon$-oblivious. 
  \end{itemize}
One can obtain a \emph{linear OKVS} if in addition require:
\begin{itemize}
  \item \textbf{Linearity: }There exists a function family $\{\row_r:\mathcal{K}\rightarrow\mathcal{V}^m\}_{r\in\{0,1\}^\kappa}$ such that $\Decode_r(P,k) = \ipd{\row_r(k)}{P}$. 
\end{itemize}
\end{definition}
The $\Encode$ process for a linear OKVS is the process of sampling a random $P$ from the set of solutions of the linear equation system $\{\ipd{\row_r(k_i)}{P} = v_i\}_{1\le i\le t}$. 

We evaluate an OKVS scheme by its rate ($\frac{\text{input length }t}{\text{output length }m}$), encoding time and decoding time. 

The work of \cite{cryptoeprint:2023/903} gives a state-of-the-art (linear) OKVS construction, featuring near optimal rate and fast decoding. 

\begin{construction}[RB-OKVS\cite{cryptoeprint:2023/903}]\label{con:OKVS_ribbon}
  Suppose $\mathcal{V} = \GG$ is a group. Let $\row_r(k)$ output a $\{0,1\}^m$ vector consisting of a width-$w$ random band. Formally speaking, $\row_r(k)$ first determine a starting point $1\le i\le m-w+1$ for the band, and then determine random $w$-bit string to fill in the positions $[i,i+w-1]$ of $\row_r(k)$ and leave the rest as 0 entries. 
  \begin{itemize}
    \item $\Encode_r(\{(k_i,v_i)\}_{1\le i\le t})\rightarrow P$ where $P$ is randomly chosen from the random band matrix system $\{\ipd{\row_r(k_i)}{P}=v_i\}_{1\le i\le t}$. If the system has no solution then output $\bot$. 
    \item $\Decode_r(P,k)\rightarrow \ipd{\row_r(k)}{P}$. 
  \end{itemize}
  
\end{construction}

Denote $m=(1+\epsilon)t$ where $\epsilon>0$ is an expansion parameter indicating the blowup to store $t$ pairs. The rate of RB-OKVS is $1/(1+\epsilon)$. The encoding can be efficiently done in $O(tw+t\log t)$ time leveraging the fact that $\row_r(k)$'s form a random band matrix. The decoding time equals to $w$ additions in $\FF$. 
To guarantee the success of $\Encode$, \cite{cryptoeprint:2023/903} suggests taking $\lambda_\stat = 2.751\epsilon w+g(\epsilon,n)$ (where $g(\epsilon,n)$ is computed empirically), and typically setting $\epsilon\in\{3\%,5\%,7\%,10\%\}$ while $w$ lying roughly between 200 and 600, with the choice of $t$ varying from $2^{10}$ to $2^{24}$.